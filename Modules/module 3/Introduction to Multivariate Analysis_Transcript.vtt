WEBVTT

1
00:00:00.000 --> 00:00:07.810
In this lecture, we want to talk about attributes of a multivariate data visualization.

2
00:00:07.810 --> 00:00:12.820
In previous modules, we've discussed univariate data visualization,

3
00:00:12.820 --> 00:00:16.520
how to create graphs and different properties of graphs,

4
00:00:16.520 --> 00:00:21.905
and all of those things focus sort of on looking at one variable in a data set.

5
00:00:21.905 --> 00:00:26.200
How are such data sets with a single variable are more and more uncommon.

6
00:00:26.200 --> 00:00:30.150
If we think of different examples such as just our classroom,

7
00:00:30.150 --> 00:00:33.085
where we might have different exams and quizzes and these things,

8
00:00:33.085 --> 00:00:34.830
we can easily create a dataset

9
00:00:34.830 --> 00:00:38.100
with several different variables that we may want to compare against.

10
00:00:38.100 --> 00:00:41.500
For example, each student in class has a name.

11
00:00:41.500 --> 00:00:44.515
We might have scores for quiz one,

12
00:00:44.515 --> 00:00:48.655
for quiz two, for quiz three and so forth,

13
00:00:48.655 --> 00:00:51.545
and each of these, and we may want to be able to create

14
00:00:51.545 --> 00:00:56.510
different plots to try to find patterns and correlations.

15
00:00:56.510 --> 00:01:00.830
And in previous lectures, we talked about things like making a histogram for one D data.

16
00:01:00.830 --> 00:01:04.120
So if I wanted to make a histogram for quiz one,

17
00:01:04.120 --> 00:01:06.510
remember we broke up the data in two different chunks.

18
00:01:06.510 --> 00:01:08.605
So if the quiz was out of 100 points,

19
00:01:08.605 --> 00:01:13.000
we might have bins from 10 to 100,

20
00:01:13.000 --> 00:01:16.285
and we would count how many students fell into each bin,

21
00:01:16.285 --> 00:01:21.595
and draw different sized bars for the number of students that fell into a bin.

22
00:01:21.595 --> 00:01:25.560
And this let us explore sort of the distribution of a single variable.

23
00:01:25.560 --> 00:01:28.255
In this lecture, what we're interested about is

24
00:01:28.255 --> 00:01:31.610
trying to start thinking about what if we have more than one variable,

25
00:01:31.610 --> 00:01:33.780
what might those plots look like?

26
00:01:33.780 --> 00:01:35.870
And with multivariate data,

27
00:01:35.870 --> 00:01:37.745
what we're interested in is really

28
00:01:37.745 --> 00:01:42.500
any statistical technique used to analyze data from more than one variable.

29
00:01:42.500 --> 00:01:47.490
And so we're going to talk not only about ways to interactively visualize the data,

30
00:01:47.490 --> 00:01:50.770
but we also want to think about ways to analyze these.

31
00:01:50.770 --> 00:01:52.700
One of the mantra is the visual analytics,

32
00:01:52.700 --> 00:01:55.650
has always been detect the expected, discover the unexpected.

33
00:01:55.650 --> 00:01:58.975
And so we want to be able to explore, interact,

34
00:01:58.975 --> 00:02:01.315
and find things that are interesting in the data,

35
00:02:01.315 --> 00:02:04.130
and process this information in a meaningful way.

36
00:02:04.130 --> 00:02:08.365
The problem is, the more dimensions that the data set has,

37
00:02:08.365 --> 00:02:12.775
the less effective its standard computational and statistical techniques become.

38
00:02:12.775 --> 00:02:14.360
We wind up with problems,

39
00:02:14.360 --> 00:02:18.700
like P fishing where you can find correlations between lots of random things.

40
00:02:18.700 --> 00:02:23.235
For example, you can go online and find correlations between

41
00:02:23.235 --> 00:02:29.045
gun violence and the altitude of the Pyrenees Mountains for example.

42
00:02:29.045 --> 00:02:32.750
And those have no meaning, no meaningful correlation.

43
00:02:32.750 --> 00:02:35.080
So we have to be careful about the things we find,

44
00:02:35.080 --> 00:02:36.490
the statistics we use,

45
00:02:36.490 --> 00:02:38.590
and the visualizations that we create,

46
00:02:38.590 --> 00:02:43.785
so that we're not accidentally lying to people about what's within their data.

47
00:02:43.785 --> 00:02:45.450
So we want to detect the unexpected,

48
00:02:45.450 --> 00:02:50.640
we also need to be careful and make sure that this has some sort of meaning behind it.

49
00:02:50.640 --> 00:02:53.230
And so in univariate visualization,

50
00:02:53.230 --> 00:02:56.205
we talked about things like histograms.

51
00:02:56.205 --> 00:02:58.675
So here we're showing another example the histogram,

52
00:02:58.675 --> 00:03:01.585
looking at maybe how to fit probability distributions.

53
00:03:01.585 --> 00:03:06.315
Here we can fit a curve to try to create some underlying probability distribution

54
00:03:06.315 --> 00:03:11.495
through techniques such as kernel density estimation.

55
00:03:11.495 --> 00:03:13.945
Here we're looking at line charts,

56
00:03:13.945 --> 00:03:17.150
and they've been expanded to handle sort of three variables,

57
00:03:17.150 --> 00:03:18.975
we're plotting three variables at once.

58
00:03:18.975 --> 00:03:22.590
But here we can see as we plot more and more line charts,

59
00:03:22.590 --> 00:03:26.215
we have more and more clutter on the screen.

60
00:03:26.215 --> 00:03:28.520
We can see from this Excel graph,

61
00:03:28.520 --> 00:03:31.115
we're not really looking at nice numbers on the plot.

62
00:03:31.115 --> 00:03:34.390
We're not really able to read the graph all that nicely.

63
00:03:34.390 --> 00:03:36.065
So when I think about those things,

64
00:03:36.065 --> 00:03:38.560
here's our example of our box and whisker plot,

65
00:03:38.560 --> 00:03:41.840
and we talked about how to create these, showing quantiles.

66
00:03:41.840 --> 00:03:44.280
So here we have the median,

67
00:03:44.280 --> 00:03:47.065
we have Q1, we have Q3.

68
00:03:47.065 --> 00:03:49.840
So median, Q1, Q3,

69
00:03:49.840 --> 00:03:52.690
as we discussed in previous lectures how to calculate those.

70
00:03:52.690 --> 00:03:56.810
We can see a skewed distribution to the negative side here.

71
00:03:56.810 --> 00:04:00.960
But we're also missing information like plot titles,

72
00:04:00.960 --> 00:04:05.165
axis labels, and some of those other things to really tell us what these data sets are.

73
00:04:05.165 --> 00:04:08.540
And these still only are really handling one variable.

74
00:04:08.540 --> 00:04:12.685
So if we think about how we might want to plot a dataset like a class

75
00:04:12.685 --> 00:04:16.795
or the nice example you'll see in other lectures about books from a library,

76
00:04:16.795 --> 00:04:18.560
then how do we handle all this information,

77
00:04:18.560 --> 00:04:23.115
we want to start thinking about new techniques for multivariate visualization.

78
00:04:23.115 --> 00:04:28.190
And really there's two main ways of presenting multivariate datasets,

79
00:04:28.190 --> 00:04:30.050
directly through a table.

80
00:04:30.050 --> 00:04:33.795
And so again, we can think about that example I made up earlier,

81
00:04:33.795 --> 00:04:36.315
where we might have everybody's name in class,

82
00:04:36.315 --> 00:04:38.740
we might have their first quiz score,

83
00:04:38.740 --> 00:04:40.425
their second quiz score,

84
00:04:40.425 --> 00:04:42.905
their third quiz score.

85
00:04:42.905 --> 00:04:45.995
So you might have Ross,

86
00:04:45.995 --> 00:04:48.370
you have some scores like this.

87
00:04:48.370 --> 00:04:51.245
We might have Jane,

88
00:04:51.245 --> 00:04:54.395
and of course Jane has some scores,

89
00:04:54.395 --> 00:04:56.875
and some other people.

90
00:04:56.875 --> 00:04:58.950
And so we have this whole table.

91
00:04:58.950 --> 00:05:02.185
And you can see right away part of the problem with this table is,

92
00:05:02.185 --> 00:05:05.610
it's hard to see any trends.

93
00:05:05.610 --> 00:05:07.590
If I have a whole lot of rows,

94
00:05:07.590 --> 00:05:09.650
it's going to be difficult to sort of comprehend those.

95
00:05:09.650 --> 00:05:11.245
If I have a whole lot of columns,

96
00:05:11.245 --> 00:05:12.820
I'm going to have more and more variables.

97
00:05:12.820 --> 00:05:15.210
So it becomes difficult to parse.

98
00:05:15.210 --> 00:05:17.690
And if we want to figure out like trends over time,

99
00:05:17.690 --> 00:05:20.010
let's say we were taking all these quizzes in a row,

100
00:05:20.010 --> 00:05:24.555
so we may actually want to look at how students improve over time.

101
00:05:24.555 --> 00:05:26.570
So we may have some sort of time series plot,

102
00:05:26.570 --> 00:05:29.870
and we may want to see if there's some students that are having trends,

103
00:05:29.870 --> 00:05:33.090
sort of going worse as the semester goes along.

104
00:05:33.090 --> 00:05:41.100
We have to think about how we might represent symbolically all of the data in the plot.

105
00:05:41.100 --> 00:05:45.300
So how do we decide which to use and when?

106
00:05:45.300 --> 00:05:49.370
So with tables, these are always our main sources of data.

107
00:05:49.370 --> 00:05:51.970
This is sort of where the ground truth is stored.

108
00:05:51.970 --> 00:05:53.200
We have some sort of document,

109
00:05:53.200 --> 00:05:54.870
whether it's an Excel file,

110
00:05:54.870 --> 00:05:57.800
a CSV file, a sequel table,

111
00:05:57.800 --> 00:06:01.310
MongoDB, whatever sort of technology we're using,

112
00:06:01.310 --> 00:06:03.460
somewhere somebody has captured data,

113
00:06:03.460 --> 00:06:06.085
and has intruded into some format.

114
00:06:06.085 --> 00:06:09.310
And this document contains individual values.

115
00:06:09.310 --> 00:06:11.210
Like I said, this could be a name,

116
00:06:11.210 --> 00:06:12.580
this could be a quiz,

117
00:06:12.580 --> 00:06:13.620
this could be a quiz,

118
00:06:13.620 --> 00:06:16.715
this could be a quiz and we have values in these.

119
00:06:16.715 --> 00:06:19.840
And this document is going to be used to compare individual values.

120
00:06:19.840 --> 00:06:21.835
I can get directly down to the number,

121
00:06:21.835 --> 00:06:23.970
and precise values are required.

122
00:06:23.970 --> 00:06:28.540
It doesn't have to just be a quantitative data like we're showing here.

123
00:06:28.540 --> 00:06:30.710
Instead of a name,

124
00:06:30.710 --> 00:06:33.830
remember this is a qualitative variable.

125
00:06:33.830 --> 00:06:35.870
So the order of the names doesn't matter,

126
00:06:35.870 --> 00:06:37.780
and one name is more important than the other.

127
00:06:37.780 --> 00:06:40.490
But we could also have things like,

128
00:06:40.490 --> 00:06:43.005
your favorite size of coffee cup,

129
00:06:43.005 --> 00:06:44.530
so small, medium or large,

130
00:06:44.530 --> 00:06:46.305
for example. So ordinal data.

131
00:06:46.305 --> 00:06:49.540
So we can contain all sorts of information in these tables,

132
00:06:49.540 --> 00:06:53.840
but the precise values of each individual record is captured.

133
00:06:53.840 --> 00:06:55.570
And within a table,

134
00:06:55.570 --> 00:06:58.270
you could also have no values.

135
00:06:58.270 --> 00:07:00.410
So you could have information that's not captured,

136
00:07:00.410 --> 00:07:02.330
maybe a person didn't thought a question,

137
00:07:02.330 --> 00:07:05.370
maybe a quiz grade wasn't entered correctly.

138
00:07:05.370 --> 00:07:11.130
And oftentimes visualization is used to quickly identify errors in the data like that,

139
00:07:11.130 --> 00:07:15.225
and to see if we can correct those or if they turn out to not be errors at all.

140
00:07:15.225 --> 00:07:19.620
And so this quantitative information to be computed,

141
00:07:19.620 --> 00:07:24.815
may involve then processing data to communicate this in different ways.

142
00:07:24.815 --> 00:07:28.145
And so, for a table,

143
00:07:28.145 --> 00:07:30.100
it's sort of these precise comparisons.

144
00:07:30.100 --> 00:07:33.885
Did Ross score more points than Jane on quiz 1?

145
00:07:33.885 --> 00:07:36.940
We can do a direct comparison between that.

146
00:07:36.940 --> 00:07:39.430
But if we're interested in sort of shapes,

147
00:07:39.430 --> 00:07:42.780
and trends, and changes in the data,

148
00:07:42.780 --> 00:07:44.380
we often want to use graphs,

149
00:07:44.380 --> 00:07:47.010
where messages contained in the shape of the values,

150
00:07:47.010 --> 00:07:51.310
and the document is going to be used to reveal relationships among different data sets.

151
00:07:51.310 --> 00:07:56.155
So for example, if I want to know the relationship between quiz 1 and quiz 2,

152
00:07:56.155 --> 00:07:58.190
I might make a scatter plot.

153
00:07:58.190 --> 00:08:00.075
We're going to talk about how to do these later.

154
00:08:00.075 --> 00:08:04.160
But if I plot quiz 1 on one axis and quiz 2 on another,

155
00:08:04.160 --> 00:08:09.645
each point here on the scatter plot is a particular person.

156
00:08:09.645 --> 00:08:12.985
So for example, if this is five and this is five,

157
00:08:12.985 --> 00:08:16.280
this person got five on Quiz 1 and five on quiz 2.

158
00:08:16.280 --> 00:08:18.710
If this is one and one,

159
00:08:18.710 --> 00:08:22.010
this person got a one on quiz 1 and a one on quiz 2.

160
00:08:22.010 --> 00:08:24.470
And as we plot more dots,

161
00:08:24.470 --> 00:08:27.390
we may find some sort of trend that

162
00:08:27.390 --> 00:08:31.710
students that did better on quiz one also did better quiz two.

163
00:08:31.710 --> 00:08:36.730
These things can be helpful for thinking about things like learning outcomes,

164
00:08:36.730 --> 00:08:39.040
they can be helpful to identify correlations,

165
00:08:39.040 --> 00:08:41.690
like if this is in the stock market,

166
00:08:41.690 --> 00:08:44.210
you may be looking for correlation between time series to

167
00:08:44.210 --> 00:08:48.135
help predict what a stock might do tomorrow,

168
00:08:48.135 --> 00:08:51.915
and all sorts of different applications in this area.

169
00:08:51.915 --> 00:08:54.330
And graphs are going to be visual displays that

170
00:08:54.330 --> 00:08:57.325
illustrate one or more relationships among entities.

171
00:08:57.325 --> 00:08:59.710
This is a shorthand way to present information,

172
00:08:59.710 --> 00:09:03.350
and it lets us see these trends and patterns and easily sort of

173
00:09:03.350 --> 00:09:07.365
get a comparison and try to comprehend what's going on.

174
00:09:07.365 --> 00:09:10.790
So what we really want to think about when we're using graphs and

175
00:09:10.790 --> 00:09:14.060
tables is thinking about what the task is.

176
00:09:14.060 --> 00:09:16.235
What are we asking the end user to do?

177
00:09:16.235 --> 00:09:17.845
Why do we need a graph?

178
00:09:17.845 --> 00:09:19.310
What are we trying to show?

179
00:09:19.310 --> 00:09:22.805
We talked about this with the Univariate data as well too.

180
00:09:22.805 --> 00:09:25.470
What questions are being answered in the graph?

181
00:09:25.470 --> 00:09:27.085
Is this the right graph to make?

182
00:09:27.085 --> 00:09:29.810
If you're not answering the questions that people want to ask,

183
00:09:29.810 --> 00:09:31.625
then maybe it's not the right visual.

184
00:09:31.625 --> 00:09:34.230
What data is going to be needed to answer those questions?

185
00:09:34.230 --> 00:09:35.810
If we haven't captured that data,

186
00:09:35.810 --> 00:09:37.560
then it doesn't matter what the graph is

187
00:09:37.560 --> 00:09:40.165
because we won't be able to help people understand.

188
00:09:40.165 --> 00:09:46.300
And finally we have to think about who's the audience from the data.

189
00:09:46.300 --> 00:09:47.610
Who are we talking to?

190
00:09:47.610 --> 00:09:49.530
How do we need to present this?

191
00:09:49.530 --> 00:09:52.775
How are they going to understand these things?

192
00:09:52.775 --> 00:09:54.660
What's their level of visual literacy?

193
00:09:54.660 --> 00:09:57.920
And how do we help people get through these?

194
00:09:57.920 --> 00:10:01.640
And so again, we talked about univariate graphs in the past.

195
00:10:01.640 --> 00:10:04.605
For example histograms, we're plotting

196
00:10:04.605 --> 00:10:09.995
probabilities and bin accounts over time or over a particular dimension.

197
00:10:09.995 --> 00:10:15.175
But, we can also move on to multiple variables as well.

198
00:10:15.175 --> 00:10:18.910
So one simple example of moving on from a bar chart in

199
00:10:18.910 --> 00:10:22.930
one dimension to two dimensions is what we call a stacked bar.

200
00:10:22.930 --> 00:10:26.170
So let's think about how this was created,

201
00:10:26.170 --> 00:10:28.410
and let's go back to our Quiz examples.

202
00:10:28.410 --> 00:10:32.395
If we have a name, we have quiz one,

203
00:10:32.395 --> 00:10:34.400
and we have quiz two,

204
00:10:34.400 --> 00:10:36.555
we have quiz three,

205
00:10:36.555 --> 00:10:39.260
and let's say each quiz out of ten points,

206
00:10:39.260 --> 00:10:41.620
so the maximum score you can get on any quiz is 10.

207
00:10:41.620 --> 00:10:44.475
So we had Ross, remember we had eight,

208
00:10:44.475 --> 00:10:46.185
a nine and a 10.

209
00:10:46.185 --> 00:10:52.405
Then we had Jane, and we had all tens here.

210
00:10:52.405 --> 00:10:56.220
So we want to think about is, when we're plotting these,

211
00:10:56.220 --> 00:11:02.110
if we plot quiz 1, the most points we can have is,

212
00:11:02.110 --> 00:11:03.310
since all of these are out of 10,

213
00:11:03.310 --> 00:11:06.425
the highest that all three of these could ever get to 30, right?

214
00:11:06.425 --> 00:11:08.280
So if we plot Ross,

215
00:11:08.280 --> 00:11:10.190
Ross is going to have his own bar,

216
00:11:10.190 --> 00:11:13.500
and Ross's first bar for quiz 1 only goes up to eight.

217
00:11:13.500 --> 00:11:16.490
So we wind up shading this in typically with some color.

218
00:11:16.490 --> 00:11:19.905
His next bar adds 9 to there, so this is 17.

219
00:11:19.905 --> 00:11:23.555
So this is 8, 17. And the final one is 27.

220
00:11:23.555 --> 00:11:26.280
So each bar is slightly longer than the other.

221
00:11:26.280 --> 00:11:30.560
Each one may have different colors or textures to represent things.

222
00:11:30.560 --> 00:11:32.715
We can also then compare Jane,

223
00:11:32.715 --> 00:11:35.100
and Jane had a 10 on quiz 1,

224
00:11:35.100 --> 00:11:36.710
a 10 on quiz 2,

225
00:11:36.710 --> 00:11:38.820
and a 10 on quiz 3.

226
00:11:38.820 --> 00:11:40.600
So all the bars are equal size.

227
00:11:40.600 --> 00:11:44.910
And then we can color those to help identify the different quizzes.

228
00:11:44.910 --> 00:11:51.865
And we can directly compare these different elements from the two people.

229
00:11:51.865 --> 00:11:55.990
And we can also do this for stock prices over time.

230
00:11:55.990 --> 00:11:58.230
So this could have been three different stocks,

231
00:11:58.230 --> 00:11:59.310
and this could have been day one,

232
00:11:59.310 --> 00:12:00.630
day two, day three.

233
00:12:00.630 --> 00:12:06.325
The problem is this lets me directly see that Jane's quiz 1 is higher than Ross's quiz 2.

234
00:12:06.325 --> 00:12:10.020
But it's really hard to compare elements in the middle,

235
00:12:10.020 --> 00:12:12.550
because now they're not grounded at the same height.

236
00:12:12.550 --> 00:12:16.210
So if I do a slightly better drawing,

237
00:12:16.210 --> 00:12:20.020
it's easy to compare those two boxes and tell me which one is longer, right?

238
00:12:20.020 --> 00:12:22.655
But if I do this,

239
00:12:22.655 --> 00:12:27.310
is one longer than two or is two longer than one?

240
00:12:27.310 --> 00:12:30.630
It gets difficult to tell,

241
00:12:30.630 --> 00:12:37.430
and so oftentimes we add in interaction where we can swap the bottom boxes with the top,

242
00:12:37.430 --> 00:12:41.650
and move things around and allow people to interactively explore different datasets.

243
00:12:41.650 --> 00:12:43.725
And this is just one example of

244
00:12:43.725 --> 00:12:46.070
sort of the multiple variables where we can

245
00:12:46.070 --> 00:12:49.890
show different elements by stacking them on top each other.

246
00:12:49.890 --> 00:12:54.510
Along with stacking, we could also think about putting elements next to each other.

247
00:12:54.510 --> 00:12:57.950
So for each person, we could have some sort of element like this.

248
00:12:57.950 --> 00:13:03.205
If this is Ross, we could have, Jane and so forth.

249
00:13:03.205 --> 00:13:08.070
But again, we wind up taking up a lot of screen real estate to do this.

250
00:13:08.070 --> 00:13:10.790
And so we're limited in the number of different then rows,

251
00:13:10.790 --> 00:13:12.395
because each person is a row,

252
00:13:12.395 --> 00:13:15.055
the number of rows that we could possibly show here.

253
00:13:15.055 --> 00:13:21.445
So again, this is one way to think about showing multiple sort of variables in a dataset.

254
00:13:21.445 --> 00:13:23.200
And over the next few lectures,

255
00:13:23.200 --> 00:13:27.800
we're going to talk about several different ways to show multiple variables.

256
00:13:27.800 --> 00:13:33.230
Some of them are common ways from scatter plots to parallel coordinate plots,

257
00:13:33.230 --> 00:13:41.160
to techniques for actually clustering and labeling data and finding patterns to them.

258
00:13:41.160 --> 00:13:43.950
Think about how we can project those onto different scatter plots

259
00:13:43.950 --> 00:13:47.000
and elements as well too. Thank you.