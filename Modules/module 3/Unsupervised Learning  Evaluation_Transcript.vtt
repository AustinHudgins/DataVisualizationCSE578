WEBVTT

1
00:00:00.000 --> 00:00:03.135
Welcome back. This is Huan Liu,

2
00:00:03.135 --> 00:00:06.255
a Professor of Computer Science and Engineering.

3
00:00:06.255 --> 00:00:12.640
We are going to discuss Unsupervised Learning Evaluation.

4
00:00:14.360 --> 00:00:20.790
So, let's assume we have many unsupervised learning algorithms.

5
00:00:20.790 --> 00:00:23.535
We would like to compare them.

6
00:00:23.535 --> 00:00:25.930
So, how can we do that?

7
00:00:26.300 --> 00:00:30.960
Or even for one algorithm,

8
00:00:30.960 --> 00:00:36.975
if I apply the algorithm to different applications,

9
00:00:36.975 --> 00:00:40.470
which application is more suitable for this algorithm?

10
00:00:40.470 --> 00:00:43.860
So, we have to answer these questions.

11
00:00:43.860 --> 00:00:50.870
Now, the simplest case is this.

12
00:00:50.870 --> 00:00:54.360
I already know I have two clusters.

13
00:00:54.360 --> 00:01:02.085
The red one, red cross should be in one cluster,

14
00:01:02.085 --> 00:01:06.570
and the blue plus should belong to another.

15
00:01:06.570 --> 00:01:13.275
So, we have ground truth,

16
00:01:13.275 --> 00:01:15.765
but that defeats the purpose.

17
00:01:15.765 --> 00:01:17.700
If we already know the two clusters,

18
00:01:17.700 --> 00:01:23.175
why should we apply any clustering algorithm?

19
00:01:23.175 --> 00:01:26.610
Only under certain circumstances,

20
00:01:26.610 --> 00:01:35.865
we really want to verify if this clustering is suitable or not.

21
00:01:35.865 --> 00:01:38.685
For example, I have some data sets.

22
00:01:38.685 --> 00:01:41.205
I know I have ground truth,

23
00:01:41.205 --> 00:01:46.490
but these data sets are similar to those data sets I'm not familiar with.

24
00:01:46.490 --> 00:01:52.765
So, I can always try my clustering algorithms on the data sets I have ground truth.

25
00:01:52.765 --> 00:01:54.540
Only in this case, it's useful.

26
00:01:54.540 --> 00:02:00.770
So, to evaluate is not easy.

27
00:02:00.770 --> 00:02:08.170
Why? Because in this case,

28
00:02:08.170 --> 00:02:11.715
I have five crosses and a one plus,

29
00:02:11.715 --> 00:02:18.900
but I cannot have two pluses and four crosses.

30
00:02:18.900 --> 00:02:23.590
So, many combinations, which one's the best?

31
00:02:25.280 --> 00:02:28.020
When we have ground truth,

32
00:02:28.020 --> 00:02:29.700
actually it's very simple.

33
00:02:29.700 --> 00:02:34.050
We can use the accuracy to keep it.

34
00:02:34.050 --> 00:02:36.675
In this case, for example,

35
00:02:36.675 --> 00:02:41.790
one plus is wrongly

36
00:02:41.790 --> 00:02:47.865
classified and two crosses are wrongly clustered in the cluster two.

37
00:02:47.865 --> 00:02:53.750
So, I have one plus two divided by six plus eight,

38
00:02:54.510 --> 00:02:58.600
equals to three over 14.

39
00:02:58.600 --> 00:03:01.785
This is the error rate.

40
00:03:01.785 --> 00:03:11.695
But then I also have five plus six divided by six plus eight, 11 over 14.

41
00:03:11.695 --> 00:03:15.630
So, you see all together should be 14, add them together.

42
00:03:15.630 --> 00:03:17.910
Or in the way,

43
00:03:17.910 --> 00:03:21.160
11 plus 14 should be what?

44
00:03:21.410 --> 00:03:24.640
This is the error rate.

45
00:03:27.590 --> 00:03:30.640
This is the accuracy.

46
00:03:37.610 --> 00:03:40.605
So, as we said,

47
00:03:40.605 --> 00:03:42.045
if we already have,

48
00:03:42.045 --> 00:03:43.790
we know this kind of thing,

49
00:03:43.790 --> 00:03:45.200
already know the ground truth.

50
00:03:45.200 --> 00:03:47.750
So, what's the use of clustering?

51
00:03:47.750 --> 00:03:58.920
That means we really need to evaluate the cases where ground truth is not available.

52
00:03:59.920 --> 00:04:04.250
What can we do when the ground truth is not available?

53
00:04:04.250 --> 00:04:07.255
So, we have to go back to our first principles.

54
00:04:07.255 --> 00:04:17.040
What is the first principle in clustering case?

55
00:04:17.040 --> 00:04:23.835
We define cohesiveness and separateness, these two measures.

56
00:04:23.835 --> 00:04:29.750
One is all cohesiveness means all the instances

57
00:04:29.750 --> 00:04:36.120
within one cluster should be closer to each other,

58
00:04:36.120 --> 00:04:41.180
and separateness means the instances from

59
00:04:41.180 --> 00:04:47.550
different clusters should be as much as separate as possible.

60
00:04:48.100 --> 00:04:52.190
So, that's why these are two issues.

61
00:04:52.190 --> 00:04:54.815
One is more cohesiveness.

62
00:04:54.815 --> 00:04:58.489
You have to be close within a cluster instances,

63
00:04:58.489 --> 00:05:01.070
within a cluster should be close to each other,

64
00:05:01.070 --> 00:05:09.120
and instances that are not in the same cluster should be far away from each other.

65
00:05:09.700 --> 00:05:14.290
Cohesiveness. How do we calculate this?

66
00:05:14.290 --> 00:05:19.260
Being close to the centroid of the cluster. This is the one way.

67
00:05:19.260 --> 00:05:22.000
So, now, let's look at this.

68
00:05:22.000 --> 00:05:24.810
This is the cluster, one cluster.

69
00:05:24.810 --> 00:05:27.150
This is another cluster.

70
00:05:27.150 --> 00:05:29.745
I only have four data points,

71
00:05:29.745 --> 00:05:31.890
one, two, one, two,

72
00:05:31.890 --> 00:05:33.540
but this is the second cluster,

73
00:05:33.540 --> 00:05:34.680
this is the first cluster,

74
00:05:34.680 --> 00:05:37.660
first cluster, second cluster.

75
00:05:39.320 --> 00:05:43.900
So, for the whole data set,

76
00:05:44.390 --> 00:05:51.830
the centroid is zero when we get a very simple case here for calculation.

77
00:05:52.890 --> 00:05:56.660
Now, for this cluster, cluster one,

78
00:05:56.660 --> 00:06:01.540
the centroid is this one plus this one divided by two.

79
00:06:01.540 --> 00:06:04.345
So, that's why it's minus 7.5.

80
00:06:04.345 --> 00:06:09.620
Likewise, this centroid is positive 7.5.

81
00:06:09.620 --> 00:06:12.870
So, how do we calculate the cohesiveness?

82
00:06:12.870 --> 00:06:17.240
So, we calculate the cohesiveness this way.

83
00:06:18.240 --> 00:06:22.630
How far is it away from the centroid?

84
00:06:22.630 --> 00:06:31.115
So, that's why you see minus 10 minus negative 7.5.

85
00:06:31.115 --> 00:06:34.740
Then, again, we need to square it.

86
00:06:34.740 --> 00:06:42.610
This is negative five minus negative 7.5 squared.

87
00:06:44.150 --> 00:06:46.695
We do the same here.

88
00:06:46.695 --> 00:06:57.360
So, it's five minus 7.5 squared and 10 minus 7.5 squared.

89
00:06:57.360 --> 00:06:59.190
So, you calculate this,

90
00:06:59.190 --> 00:07:01.600
and it becomes 25.

91
00:07:02.210 --> 00:07:06.300
Now, we discuss separateness.

92
00:07:06.300 --> 00:07:13.745
So, clusters centroids being far from the mean of entire data set.

93
00:07:13.745 --> 00:07:16.729
This is one way to calculate.

94
00:07:16.729 --> 00:07:19.530
So, now, for this data set,

95
00:07:19.530 --> 00:07:21.435
we have this centroid.

96
00:07:21.435 --> 00:07:23.265
For this data set,

97
00:07:23.265 --> 00:07:27.645
we have this centroid, cluster one, cluster two.

98
00:07:27.645 --> 00:07:31.155
Each cluster has its centroid.

99
00:07:31.155 --> 00:07:39.470
So, separateness is, I just need to calculate this centroid with this.

100
00:07:39.470 --> 00:07:44.340
The entire data is mean and this centroid.

101
00:07:45.780 --> 00:07:52.540
With this entire data as me.

102
00:07:52.540 --> 00:08:03.325
So, this negative 7.25 minus 0 squared plus 7.5 minus 0 squared.

103
00:08:03.325 --> 00:08:08.860
Separateness should be the larger the better.

104
00:08:08.860 --> 00:08:15.980
Okay. Because that means the centroids are moving far away from each other.

105
00:08:17.220 --> 00:08:22.935
Now, we discuss another measure,

106
00:08:22.935 --> 00:08:27.315
it's called silhouette index.

107
00:08:27.315 --> 00:08:34.515
So, we are interested in clusters that are both cohesive and separate.

108
00:08:34.515 --> 00:08:43.510
So, silhouette index, it compares average distance value between

109
00:08:43.510 --> 00:08:47.455
instances in the same cluster to

110
00:08:47.455 --> 00:08:53.510
average distance value between instances in the same cluster.

111
00:08:56.310 --> 00:09:01.780
This is very much similar to the one we already talked about.

112
00:09:01.780 --> 00:09:10.330
But in the well clustered data set,

113
00:09:10.330 --> 00:09:17.920
average distance between instances in the same cluster should be small,

114
00:09:17.920 --> 00:09:26.155
and the average distance between instances in different clusters should be large.

115
00:09:26.155 --> 00:09:34.160
So, we still go with cohesiveness and separateness. How do we do that?

116
00:09:38.250 --> 00:09:41.590
So, for any instance x,

117
00:09:41.590 --> 00:09:48.595
that is a member of cluster C any instance x.

118
00:09:48.595 --> 00:09:55.105
So, we try to find members in the same cluster,

119
00:09:55.105 --> 00:09:57.160
but it's not x,

120
00:09:57.160 --> 00:09:58.795
we calculate their distance,

121
00:09:58.795 --> 00:10:01.030
we add them together,

122
00:10:01.030 --> 00:10:11.155
and divide by the number of total number of instances in the cluster C minus one,

123
00:10:11.155 --> 00:10:15.895
this is called cohesion.

124
00:10:15.895 --> 00:10:20.310
We computed the within cluster average distance,

125
00:10:20.310 --> 00:10:24.345
this is the within-cluster for each given cluster.

126
00:10:24.345 --> 00:10:28.530
Then computed the average distance between x and C,

127
00:10:28.530 --> 00:10:31.710
and instance is in clust G,

128
00:10:31.710 --> 00:10:35.215
that's another cluster, okay?

129
00:10:35.215 --> 00:10:44.770
G is the closest to 2x in terms of the average distance between x and C,

130
00:10:44.770 --> 00:10:47.410
and members of G. Now,

131
00:10:47.410 --> 00:10:53.275
why we need to be careful about to this closest to x,

132
00:10:53.275 --> 00:10:58.870
because we cannot just assume we only have two clusters,

133
00:10:58.870 --> 00:11:04.540
C and G. What if we have more than two clusters?

134
00:11:04.540 --> 00:11:06.265
In this such a case,

135
00:11:06.265 --> 00:11:11.290
we only need to consider G and

136
00:11:11.290 --> 00:11:17.425
C. It's a very smart way to avoid unnecessary calculation.

137
00:11:17.425 --> 00:11:19.675
So, now what do we do is this,

138
00:11:19.675 --> 00:11:23.290
for x, so G is not equal to C,

139
00:11:23.290 --> 00:11:25.375
but at closest to x,

140
00:11:25.375 --> 00:11:29.650
then for every instance in G,

141
00:11:29.650 --> 00:11:32.120
we calculate the distance.

142
00:11:32.790 --> 00:11:35.900
Then we sum them up,

143
00:11:36.150 --> 00:11:42.520
this minimum is we find that the closest to G. So,

144
00:11:42.520 --> 00:11:45.835
now we have this ax and bx.

145
00:11:45.835 --> 00:11:52.490
So, we'll use an example to show you how to calculate this.

146
00:11:54.450 --> 00:11:59.515
For silhouette index, our interest is

147
00:11:59.515 --> 00:12:08.420
clustering's where a of x should be smaller than b of x.

148
00:12:08.640 --> 00:12:14.890
So, basically, this one says instances within the cluster,

149
00:12:14.890 --> 00:12:24.480
the value should be smaller than those they are not in the same cluster.

150
00:12:24.480 --> 00:12:30.180
Because b calculates the average distance

151
00:12:30.180 --> 00:12:38.995
with those are not in C. A is about within cluster C,

152
00:12:38.995 --> 00:12:43.000
and B is about C and G. So,

153
00:12:43.000 --> 00:12:47.815
silhouette, can take values between one and -101.

154
00:12:47.815 --> 00:12:52.105
The best case happens when all x,

155
00:12:52.105 --> 00:12:56.890
for all x this equals to 0,

156
00:12:56.890 --> 00:13:00.055
and this is greater than,

157
00:13:00.055 --> 00:13:02.980
this is just the same as here.

158
00:13:02.980 --> 00:13:05.695
This is our goal.

159
00:13:05.695 --> 00:13:13.460
So, that's why we have this S for every x because I have many data points.

160
00:13:13.740 --> 00:13:16.885
So, I have n data points.

161
00:13:16.885 --> 00:13:18.640
So, for every data point,

162
00:13:18.640 --> 00:13:20.335
I have to calculate to this,

163
00:13:20.335 --> 00:13:23.320
b of x minus a of x,

164
00:13:23.320 --> 00:13:31.510
divided by max of this b of x and choose the bigger one in the denominator.

165
00:13:31.510 --> 00:13:35.365
So, then we add them altogether.

166
00:13:35.365 --> 00:13:41.755
For each instance, we should have this S value,

167
00:13:41.755 --> 00:13:46.014
we add them altogether divided by number of total number of instances,

168
00:13:46.014 --> 00:13:49.520
that's the silhouette value.

169
00:13:50.220 --> 00:13:52.975
Now, let's look at the example,

170
00:13:52.975 --> 00:13:59.830
for your convenience I include a of x here definition,

171
00:13:59.830 --> 00:14:01.690
and b of x also here,

172
00:14:01.690 --> 00:14:04.390
then S here and the silhouette here,

173
00:14:04.390 --> 00:14:07.490
then let us see how we calculate.

174
00:14:08.430 --> 00:14:13.255
We have four data points,

175
00:14:13.255 --> 00:14:16.180
so x11 is here,

176
00:14:16.180 --> 00:14:20.575
x11, this is one set,

177
00:14:20.575 --> 00:14:24.280
this is second set calculation.

178
00:14:24.280 --> 00:14:26.960
Now, let's look at this.

179
00:14:27.000 --> 00:14:35.725
So, this one for x11 minus because we only have two data points, right?

180
00:14:35.725 --> 00:14:45.880
So, negative 10 minus negative five and squared is 25.

181
00:14:45.880 --> 00:14:51.925
For B x11, how do we calculate?

182
00:14:51.925 --> 00:14:58.675
That's what we do, B we have to divide the number of data points in G, right?

183
00:14:58.675 --> 00:15:07.100
This two, so now that's what we do,

184
00:15:08.280 --> 00:15:12.410
negative 10 minus five,

185
00:15:15.630 --> 00:15:20.815
then this is the distance squared -10

186
00:15:20.815 --> 00:15:29.620
minus 10 n squared,

187
00:15:29.620 --> 00:15:31.600
this is the value,

188
00:15:31.600 --> 00:15:39.310
but now for the silhouette what do we do is silhouette is b of x minus a of x,

189
00:15:39.310 --> 00:15:41.515
b of x minus a of x,

190
00:15:41.515 --> 00:15:47.830
this one minus this divided by the largest amount between the two,

191
00:15:47.830 --> 00:15:49.045
so we have this,

192
00:15:49.045 --> 00:15:51.880
so the value and 0.29.

193
00:15:51.880 --> 00:15:55.045
Now, let's look at one more example.

194
00:15:55.045 --> 00:16:02.860
So, let's say we pick this value, x22.

195
00:16:02.860 --> 00:16:05.575
We want to work on this x22.

196
00:16:05.575 --> 00:16:10.525
So, now, look at this,

197
00:16:10.525 --> 00:16:12.370
because we only have one value,

198
00:16:12.370 --> 00:16:13.930
so there is no such a thing here,

199
00:16:13.930 --> 00:16:17.185
so it's 10 minus five,

200
00:16:17.185 --> 00:16:21.940
10 minus five, 10 minus five here,

201
00:16:21.940 --> 00:16:24.835
10 minus five squared 25.

202
00:16:24.835 --> 00:16:30.565
Now, for bx22, we have to calculate with the G,

203
00:16:30.565 --> 00:16:31.945
this is this case.

204
00:16:31.945 --> 00:16:38.470
So, likewise we have to do is one, two.

205
00:16:38.470 --> 00:16:46.130
So, 10 minus negative five.

206
00:16:47.520 --> 00:16:51.820
This should be here to next to five,

207
00:16:51.820 --> 00:16:55.480
and 10 minus five.

208
00:16:55.480 --> 00:17:00.370
These two cases, one and two, two.

209
00:17:00.370 --> 00:17:05.485
So, we have 10 minus five,

210
00:17:05.485 --> 00:17:10.225
10 minus negative five,10 minus negative 10,

211
00:17:10.225 --> 00:17:12.385
10 minus negative five,

212
00:17:12.385 --> 00:17:15.355
10 minus negative 10.

213
00:17:15.355 --> 00:17:17.275
So, we have these values,

214
00:17:17.275 --> 00:17:19.790
and then we calculate we have this decimal.

215
00:17:19.790 --> 00:17:23.645
It's a symmetrical so we know these calculations are correct.

216
00:17:23.645 --> 00:17:27.529
Then likewise we calculate x 21,

217
00:17:27.529 --> 00:17:31.590
x 12, so we have these values,

218
00:17:31.590 --> 00:17:33.225
then we add them up,

219
00:17:33.225 --> 00:17:38.315
divide it by how many numbers of various instances do we have,

220
00:17:38.315 --> 00:17:41.855
we have n equals four,

221
00:17:41.855 --> 00:17:43.235
so we divide it by four.

222
00:17:43.235 --> 00:17:53.170
So, we can see the value should be somewhere between 0.92 and 0.84.

223
00:17:53.170 --> 00:18:02.570
Now, we have a silhouette index to measure the clustering result.

224
00:18:02.570 --> 00:18:07.520
That's the end of clustering evaluation

225
00:18:07.520 --> 00:18:14.100
or the evaluation of unsupervised learning or both.

226
00:18:14.190 --> 00:18:21.559
So, this method can be applied to any clustering algorithms,

227
00:18:21.559 --> 00:18:27.110
not necessarily just for k-means. Thank you.